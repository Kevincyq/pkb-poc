"""
æ–‡ä»¶æœåŠ¡ API
æä¾›æ–‡ä»¶ç¼©ç•¥å›¾ç”Ÿæˆå’Œè®¿é—®åŠŸèƒ½
"""

from fastapi import APIRouter, HTTPException, Response, Depends
from fastapi.responses import FileResponse
import os
import logging
from pathlib import Path
from PIL import Image
import io
import hashlib
import time
from sqlalchemy.orm import Session
from app.db import SessionLocal
from app.models import Content, Chunk, ContentCategory

router = APIRouter()
logger = logging.getLogger(__name__)

def get_db():
    db = SessionLocal()
    try: 
        yield db
    finally: 
        db.close()

# æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
SUPPORTED_IMAGE_FORMATS = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'}

# ç¼©ç•¥å›¾é…ç½®
THUMBNAIL_SIZE = (300, 200)
THUMBNAIL_QUALITY = 85

# ç¼©ç•¥å›¾å­˜å‚¨ç›®å½•
THUMBNAIL_DIR = Path("/tmp/pkb_thumbnails")
THUMBNAIL_DIR.mkdir(exist_ok=True)

def get_file_path(filename: str, db: Session) -> Path:
    """è·å–æ–‡ä»¶çš„å®é™…è·¯å¾„ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæ”¯æŒåŸå§‹æ–‡ä»¶åå’Œå­˜å‚¨æ–‡ä»¶åæ˜ å°„"""
    logger.info(f"ğŸ” Looking for file: {filename}")
    logger.info(f"ğŸ” Filename type: {type(filename)}, repr: {repr(filename)}")
    
    try:
        # URLè§£ç æ–‡ä»¶åï¼ˆå¤„ç†å‰ç«¯ä¼ æ¥çš„ç¼–ç æ–‡ä»¶åï¼‰
        import urllib.parse
        decoded_filename = urllib.parse.unquote(filename)
        logger.info(f"ğŸ”“ Decoded filename: {decoded_filename}")
        logger.info(f"ğŸ”“ Decoded type: {type(decoded_filename)}, repr: {repr(decoded_filename)}")
        
        # 1. ä¼˜å…ˆé€šè¿‡æ•°æ®åº“æŸ¥æ‰¾ï¼ˆæ”¯æŒåŸå§‹æ–‡ä»¶åå’Œå­˜å‚¨æ–‡ä»¶åï¼‰
        logger.info(f"ğŸ” Step 1: å°è¯•é€šè¿‡source_uriæŸ¥æ‰¾: webui://{filename}")
        content = db.query(Content).filter(
            Content.source_uri == f"webui://{filename}"
        ).first()
        
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•è§£ç åçš„æ–‡ä»¶å
        if not content:
            logger.info(f"ğŸ” Step 2: å°è¯•é€šè¿‡è§£ç åçš„source_uriæŸ¥æ‰¾: webui://{decoded_filename}")
            content = db.query(Content).filter(
                Content.source_uri == f"webui://{decoded_filename}"
            ).first()
        
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•é€šè¿‡åŸå§‹æ–‡ä»¶åæŸ¥æ‰¾
        if not content:
            logger.info(f"ğŸ” Step 3: å°è¯•é€šè¿‡titleæŸ¥æ‰¾: {filename}")
            content = db.query(Content).filter(
                Content.title == filename
            ).first()
            
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•è§£ç åçš„åŸå§‹æ–‡ä»¶å
        if not content:
            logger.info(f"ğŸ” Step 4: å°è¯•é€šè¿‡è§£ç åçš„titleæŸ¥æ‰¾: {decoded_filename}")
            content = db.query(Content).filter(
                Content.title == decoded_filename
            ).first()
        
        if content:
            logger.info(f"âœ… Found content in database: id={content.id}, title={content.title}, source_uri={content.source_uri}")
            logger.info(f"ğŸ“‹ Content meta: {content.meta}")
            
            if content.meta and isinstance(content.meta, dict):
                # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“ä¸­å­˜å‚¨çš„æ–‡ä»¶è·¯å¾„
                actual_path = content.meta.get('file_path')
                if actual_path:
                    file_path = Path(actual_path)
                    logger.info(f"ğŸ“‚ Database file path: {actual_path}, exists: {file_path.exists()}")
                    if file_path.exists():
                        logger.info(f"âœ… Found file via database file_path: {filename} -> {actual_path}")
                        return file_path
                    else:
                        logger.warning(f"âš ï¸ Database file path does not exist: {actual_path}")
            
                # å¦‚æœæ•°æ®åº“è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨å­˜å‚¨æ–‡ä»¶å
                stored_filename = content.meta.get('stored_filename')
                if stored_filename:
                    stored_path = Path("/app/uploads") / stored_filename
                    logger.info(f"ğŸ“‚ Trying stored_filename: {stored_filename}, path: {stored_path}, exists: {stored_path.exists()}")
                    if stored_path.exists():
                        logger.info(f"âœ… Found file via stored filename: {filename} -> {stored_path}")
                        return stored_path
            
            # å¦‚æœå‰ç«¯ä¼ æ¥çš„æ˜¯åŸå§‹æ–‡ä»¶åï¼Œä½†æ•°æ®åº“ä¸­å­˜å‚¨çš„æ˜¯å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
            # å°è¯•é€šè¿‡source_uriè·å–å®é™…çš„å­˜å‚¨æ–‡ä»¶å
            if content.source_uri and content.source_uri.startswith('webui://'):
                actual_stored_filename = content.source_uri.replace('webui://', '')
                stored_path = Path("/app/uploads") / actual_stored_filename
                logger.info(f"ğŸ“‚ Trying source_uri filename: {actual_stored_filename}, path: {stored_path}, exists: {stored_path.exists()}")
                if stored_path.exists():
                    logger.info(f"âœ… Found file via source_uri: {filename} -> {stored_path}")
                    return stored_path
                else:
                    logger.warning(f"âš ï¸ Source URI file not found: {stored_path}")
        else:
            logger.warning(f"âŒ No database record found for: {filename}")
        
        # 2. å°è¯•ç›´æ¥åŒ¹é…æ–‡ä»¶åï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        possible_locations = [
            Path("/app/uploads") / filename,
            Path("/data/uploads") / filename,
            Path("/var/uploads") / filename,
            Path("/uploads") / filename,
            Path("/tmp/pkb_uploads") / filename,  # ä¸´æ—¶ç›®å½•æ”¾æœ€å
        ]
        
        for file_path in possible_locations:
            if file_path.exists():
                logger.info(f"Found file via direct match: {filename} -> {file_path}")
                return file_path
        
        # 3. å°è¯•åœ¨å„ä¸ªç›®å½•ä¸­æŒ‰æ–‡ä»¶åæ¨¡ç³ŠåŒ¹é…ï¼ˆè€Œéä»…æŒ‰æ‰©å±•åï¼‰
        target_name = Path(filename).stem.lower()  # è·å–ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶å
        target_extension = Path(filename).suffix.lower()
        search_dirs = [Path("/app/uploads"), Path("/data/uploads"), Path("/var/uploads"), Path("/uploads"), Path("/tmp/pkb_uploads")]
        
        for base_dir in search_dirs:
            logger.info(f"Checking directory: {base_dir}, exists: {base_dir.exists()}")
            if not base_dir.exists():
                continue
                
            # åˆ—å‡ºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ç”¨äºè°ƒè¯•
            try:
                all_files = list(base_dir.rglob("*"))
                logger.info(f"Files in {base_dir}: {[f.name for f in all_files if f.is_file()][:10]}")  # åªæ˜¾ç¤ºå‰10ä¸ª
            except Exception as e:
                logger.warning(f"Could not list files in {base_dir}: {e}")
                
            # é¦–å…ˆå°è¯•ç²¾ç¡®çš„æ–‡ä»¶ååŒ¹é…ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            exact_matches = []
            fuzzy_matches = []
            
            for file in base_dir.rglob(f"*{target_extension}"):
                if file.is_file():
                    file_stem = file.stem.lower()
                    # ç²¾ç¡®åŒ¹é…æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
                    if file_stem == target_name:
                        exact_matches.append(file)
                    # æ¨¡ç³ŠåŒ¹é…ï¼ˆåŒ…å«ç›®æ ‡æ–‡ä»¶åï¼‰
                    elif target_name in file_stem or file_stem in target_name:
                        fuzzy_matches.append(file)
            
            logger.info(f"Found {len(exact_matches)} exact matches and {len(fuzzy_matches)} fuzzy matches for {filename}")
            
            # ä¼˜å…ˆè¿”å›ç²¾ç¡®åŒ¹é…
            if exact_matches:
                # å¦‚æœæœ‰å¤šä¸ªç²¾ç¡®åŒ¹é…ï¼Œé€‰æ‹©æœ€æ–°çš„
                best_match = max(exact_matches, key=lambda f: f.stat().st_mtime)
                logger.info(f"Found file via exact match: {filename} -> {best_match}")
                return best_match
            
            # å…¶æ¬¡è¿”å›æ¨¡ç³ŠåŒ¹é…ä¸­æœ€ç›¸ä¼¼çš„
            elif fuzzy_matches:
                # æŒ‰æ–‡ä»¶åç›¸ä¼¼åº¦æ’åºï¼Œé€‰æ‹©æœ€ç›¸ä¼¼çš„
                def similarity_score(file_path):
                    file_stem = file_path.stem.lower()
                    # è®¡ç®—ç®€å•çš„ç›¸ä¼¼åº¦åˆ†æ•°
                    if target_name == file_stem:
                        return 100
                    elif target_name in file_stem:
                        return 80 - abs(len(file_stem) - len(target_name))
                    elif file_stem in target_name:
                        return 70 - abs(len(target_name) - len(file_stem))
                    else:
                        return 0
                
                best_match = max(fuzzy_matches, key=similarity_score)
                logger.warning(f"Found file via fuzzy match: {filename} -> {best_match} (this may cause thumbnail issues)")
                return best_match
        
        # 4. æœ€åçš„å›é€€
        logger.error(f"File not found anywhere: {filename}")
        return Path("/tmp/pkb_uploads") / filename
        
    except Exception as e:
        logger.error(f"Error in get_file_path for {filename}: {e}")
        return Path("/tmp/pkb_uploads") / filename

def get_thumbnail_path(original_file_path: Path, requested_filename: str = None) -> Path:
    """
    ç”Ÿæˆç¼©ç•¥å›¾æ–‡ä»¶è·¯å¾„
    
    Args:
        original_file_path: å®é™…æ–‡ä»¶è·¯å¾„
        requested_filename: ç”¨æˆ·è¯·æ±‚çš„æ–‡ä»¶åï¼ˆç”¨äºç¡®ä¿ç¼“å­˜é”®çš„ä¸€è‡´æ€§ï¼‰
    """
    # ä¼˜å…ˆä½¿ç”¨è¯·æ±‚çš„æ–‡ä»¶åï¼Œç¡®ä¿ç¼“å­˜é”®ä¸€è‡´æ€§
    if requested_filename:
        base_name = Path(requested_filename).stem
    else:
        base_name = original_file_path.stem
    
    # ä½¿ç”¨æ–‡ä»¶åã€å¤§å°å’Œä¿®æ”¹æ—¶é—´ç”Ÿæˆå”¯ä¸€æ ‡è¯†
    file_stat = original_file_path.stat()
    
    # ç”Ÿæˆæ›´ç¨³å®šçš„ç¼“å­˜é”®ï¼šåŸºäºè¯·æ±‚çš„æ–‡ä»¶åè€Œéå®é™…è·¯å¾„
    content = f"{base_name}_{file_stat.st_size}_{file_stat.st_mtime}"
    file_hash = hashlib.md5(content.encode()).hexdigest()
    
    thumbnail_filename = f"{base_name}_{file_hash[:8]}.jpg"  # ä½¿ç”¨æ–‡ä»¶åå‰ç¼€ + çŸ­å“ˆå¸Œ
    return THUMBNAIL_DIR / thumbnail_filename

def generate_thumbnail(image_path: Path, max_size: tuple = THUMBNAIL_SIZE) -> bytes:
    """ç”Ÿæˆå›¾ç‰‡ç¼©ç•¥å›¾"""
    try:
        with Image.open(image_path) as img:
            # è½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆå¤„ç†RGBAç­‰æ ¼å¼ï¼‰
            if img.mode in ('RGBA', 'LA', 'P'):
                # åˆ›å»ºç™½è‰²èƒŒæ™¯
                background = Image.new('RGB', img.size, (255, 255, 255))
                if img.mode == 'P':
                    img = img.convert('RGBA')
                background.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
                img = background
            elif img.mode != 'RGB':
                img = img.convert('RGB')
            
            # ç”Ÿæˆç¼©ç•¥å›¾
            img.thumbnail(max_size, Image.Resampling.LANCZOS)
            
            # ä¿å­˜åˆ°å†…å­˜
            output = io.BytesIO()
            img.save(output, format='JPEG', quality=THUMBNAIL_QUALITY, optimize=True)
            return output.getvalue()
            
    except Exception as e:
        logger.error(f"Failed to generate thumbnail for {image_path}: {e}")
        raise

def create_and_save_thumbnail(image_path: Path, requested_filename: str = None) -> Path:
    """åˆ›å»ºå¹¶ä¿å­˜ç¼©ç•¥å›¾åˆ°ç£ç›˜"""
    thumbnail_path = get_thumbnail_path(image_path, requested_filename)
    
    # å¦‚æœç¼©ç•¥å›¾å·²å­˜åœ¨ä¸”æ˜¯æœ€æ–°çš„ï¼Œç›´æ¥è¿”å›
    if thumbnail_path.exists():
        return thumbnail_path
    
    try:
        # ç”Ÿæˆç¼©ç•¥å›¾æ•°æ®
        thumbnail_data = generate_thumbnail(image_path)
        
        # ä¿å­˜åˆ°ç£ç›˜
        with open(thumbnail_path, 'wb') as f:
            f.write(thumbnail_data)
        
        logger.info(f"Created thumbnail: {thumbnail_path}")
        return thumbnail_path
        
    except Exception as e:
        logger.error(f"Failed to create thumbnail for {image_path}: {e}")
        raise

def get_or_create_thumbnail(image_path: Path, requested_filename: str = None) -> Path:
    """è·å–æˆ–åˆ›å»ºç¼©ç•¥å›¾"""
    thumbnail_path = get_thumbnail_path(image_path, requested_filename)
    
    # æ£€æŸ¥ç¼©ç•¥å›¾æ˜¯å¦å­˜åœ¨ä¸”æ˜¯æœ€æ–°çš„
    if thumbnail_path.exists():
        return thumbnail_path
    
    # åˆ›å»ºæ–°çš„ç¼©ç•¥å›¾
    return create_and_save_thumbnail(image_path, requested_filename)

@router.get("/thumbnail/{filename}")
async def get_file_thumbnail(filename: str, db: Session = Depends(get_db)):
    """
    è·å–æ–‡ä»¶ç¼©ç•¥å›¾ï¼ˆæŒä¹…åŒ–ç­–ç•¥ï¼‰
    """
    try:
        logger.info(f"Requesting thumbnail for: {filename}")
        
        file_path = get_file_path(filename, db)
        logger.info(f"Found file path: {file_path}")
        
        if not file_path.exists():
            logger.error(f"File does not exist: {file_path}")
            raise HTTPException(status_code=404, detail=f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
        file_extension = file_path.suffix.lower()
        if file_extension not in SUPPORTED_IMAGE_FORMATS:
            logger.error(f"Unsupported image format: {file_extension}")
            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼: {file_extension}")
        
        # è·å–æˆ–åˆ›å»ºç¼©ç•¥å›¾ï¼Œä¼ å…¥è¯·æ±‚çš„æ–‡ä»¶åä»¥ç¡®ä¿ç¼“å­˜ä¸€è‡´æ€§
        thumbnail_path = get_or_create_thumbnail(file_path, filename)
        logger.info(f"Generated thumbnail path: {thumbnail_path}")
        
        if not thumbnail_path or not thumbnail_path.exists():
            logger.error(f"Failed to create thumbnail: {thumbnail_path}")
            raise HTTPException(status_code=500, detail="ç¼©ç•¥å›¾ç”Ÿæˆå¤±è´¥")
        
        # è¿”å›ç¼©ç•¥å›¾æ–‡ä»¶
        return FileResponse(
            path=str(thumbnail_path),
            media_type="image/jpeg",
            filename=f"thumbnail_{filename}",
            headers={
                "Cache-Control": "public, max-age=86400",  # ç¼“å­˜24å°æ—¶
                "ETag": f'"{thumbnail_path.stat().st_mtime}"'  # ä½¿ç”¨ä¿®æ”¹æ—¶é—´ä½œä¸ºETag
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting thumbnail for {filename}: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–ç¼©ç•¥å›¾å¤±è´¥: {str(e)}")

@router.get("/{filename}")
async def get_file(filename: str, db: Session = Depends(get_db)):
    """
    è·å–åŸå§‹æ–‡ä»¶ï¼ˆç”¨äºé¢„è§ˆå’Œä¸‹è½½ï¼‰
    """
    try:
        logger.info(f"Requesting file: {filename}")
        file_path = get_file_path(filename, db)
        logger.info(f"Found file path: {file_path}")
        
        if not file_path.exists():
            logger.error(f"File does not exist: {file_path}")
            raise HTTPException(status_code=404, detail=f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
        
        # åˆ¤æ–­æ–‡ä»¶ç±»å‹
        file_extension = file_path.suffix.lower()
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹è®¾ç½®media_type
        media_type_map = {
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.gif': 'image/gif',
            '.bmp': 'image/bmp',
            '.webp': 'image/webp',
            '.pdf': 'application/pdf',
            '.txt': 'text/plain',
            '.md': 'text/markdown',
            '.json': 'application/json',
        }
        
        media_type = media_type_map.get(file_extension, 'application/octet-stream')
        
        return FileResponse(
            path=str(file_path),
            media_type=media_type,
            filename=filename,
            headers={
                "Cache-Control": "public, max-age=3600",
                "Content-Disposition": f'inline; filename="{filename}"'  # inlineè¡¨ç¤ºæµè§ˆå™¨å†…é¢„è§ˆ
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error serving file {filename}: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡ä»¶å¤±è´¥: {str(e)}")

@router.get("/raw/{filename}")
async def get_raw_file(filename: str, db: Session = Depends(get_db)):
    """
    è·å–åŸå§‹æ–‡ä»¶ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
    """
    return await get_file(filename, db)

# å…¬å…±å‡½æ•°ï¼Œä¾›å…¶ä»–æ¨¡å—è°ƒç”¨
def pregenerate_thumbnail_if_image(file_path: Path) -> bool:
    """
    å¦‚æœæ˜¯å›¾ç‰‡æ–‡ä»¶ï¼Œé¢„ç”Ÿæˆç¼©ç•¥å›¾
    è¿”å›æ˜¯å¦æˆåŠŸç”Ÿæˆç¼©ç•¥å›¾
    """
    try:
        if not file_path.exists():
            return False
            
        file_extension = file_path.suffix.lower()
        if file_extension not in SUPPORTED_IMAGE_FORMATS:
            return False
        
        # é¢„ç”Ÿæˆç¼©ç•¥å›¾
        thumbnail_path = create_and_save_thumbnail(file_path, file_path.name)
        logger.info(f"Pre-generated thumbnail for {file_path.name}: {thumbnail_path}")
        return True
        
    except Exception as e:
        logger.error(f"Failed to pre-generate thumbnail for {file_path}: {e}")
        return False

@router.post("/pregenerate-thumbnail")
async def pregenerate_thumbnail(filename: str, db: Session = Depends(get_db)):
    """
    æ‰‹åŠ¨é¢„ç”Ÿæˆç¼©ç•¥å›¾ï¼ˆç”¨äºæ‰¹é‡å¤„ç†ï¼‰
    """
    try:
        file_path = get_file_path(filename, db)
        logger.info(f"Attempting to pregenerate thumbnail for {filename}, found path: {file_path}")
        
        if not file_path.exists():
            return {"status": "error", "message": f"æ–‡ä»¶ä¸å­˜åœ¨: {filename} (searched path: {file_path})"}
        
        success = pregenerate_thumbnail_if_image(file_path)
        
        if success:
            return {"status": "success", "message": f"ç¼©ç•¥å›¾å·²ç”Ÿæˆ: {filename}"}
        else:
            return {"status": "skipped", "message": f"è·³è¿‡éå›¾ç‰‡æ–‡ä»¶: {filename} (extension: {file_path.suffix})"}
            
    except Exception as e:
        logger.error(f"Error pre-generating thumbnail for {filename}: {e}")
        raise HTTPException(status_code=500, detail=f"é¢„ç”Ÿæˆç¼©ç•¥å›¾å¤±è´¥: {str(e)}")

@router.post("/batch-pregenerate-thumbnails")
async def batch_pregenerate_thumbnails(db: Session = Depends(get_db)):
    """
    æ‰¹é‡é¢„ç”Ÿæˆæ‰€æœ‰å›¾ç‰‡çš„ç¼©ç•¥å›¾
    """
    try:
        # æŸ¥è¯¢æ‰€æœ‰å›¾ç‰‡ç±»å‹çš„å†…å®¹
        image_contents = db.query(Content).filter(Content.modality == 'image').all()
        
        results = []
        success_count = 0
        error_count = 0
        
        for content in image_contents:
            filename = content.title
            try:
                file_path = get_file_path(filename, db)
                
                if file_path.exists():
                    success = pregenerate_thumbnail_if_image(file_path)
                    if success:
                        results.append({"filename": filename, "status": "success"})
                        success_count += 1
                    else:
                        results.append({"filename": filename, "status": "skipped", "reason": "not_image"})
                else:
                    results.append({"filename": filename, "status": "error", "reason": "file_not_found"})
                    error_count += 1
                    
            except Exception as e:
                results.append({"filename": filename, "status": "error", "reason": str(e)})
                error_count += 1
        
        return {
            "total_processed": len(image_contents),
            "success_count": success_count,
            "error_count": error_count,
            "results": results
        }
        
    except Exception as e:
        logger.error(f"Error in batch pregenerate thumbnails: {e}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡ç”Ÿæˆç¼©ç•¥å›¾å¤±è´¥: {str(e)}")

@router.delete("/thumbnails/cleanup")
async def cleanup_old_thumbnails(max_age_days: int = 7):
    """
    æ¸…ç†æ—§çš„ç¼©ç•¥å›¾æ–‡ä»¶
    """
    try:
        current_time = time.time()
        max_age_seconds = max_age_days * 24 * 3600
        cleaned_count = 0
        
        for thumbnail_file in THUMBNAIL_DIR.glob("*.jpg"):
            try:
                file_age = current_time - thumbnail_file.stat().st_mtime
                if file_age > max_age_seconds:
                    thumbnail_file.unlink()
                    cleaned_count += 1
                    logger.info(f"Cleaned old thumbnail: {thumbnail_file}")
            except Exception as e:
                logger.warning(f"Failed to clean thumbnail {thumbnail_file}: {e}")
        
        return {
            "status": "success", 
            "cleaned_count": cleaned_count,
            "message": f"æ¸…ç†äº† {cleaned_count} ä¸ªè¶…è¿‡ {max_age_days} å¤©çš„ç¼©ç•¥å›¾"
        }
        
    except Exception as e:
        logger.error(f"Error during thumbnail cleanup: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†ç¼©ç•¥å›¾å¤±è´¥: {str(e)}")

@router.get("/thumbnails/stats")
async def get_thumbnail_stats():
    """
    è·å–ç¼©ç•¥å›¾ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        thumbnail_files = list(THUMBNAIL_DIR.glob("*.jpg"))
        total_count = len(thumbnail_files)
        
        total_size = sum(f.stat().st_size for f in thumbnail_files if f.exists())
        total_size_mb = total_size / (1024 * 1024)
        
        return {
            "thumbnail_count": total_count,
            "total_size_mb": round(total_size_mb, 2),
            "storage_path": str(THUMBNAIL_DIR),
            "average_size_kb": round(total_size / total_count / 1024, 2) if total_count > 0 else 0
        }
        
    except Exception as e:
        logger.error(f"Error getting thumbnail stats: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")

@router.get("/debug/{filename}")
async def debug_file_path(filename: str, db: Session = Depends(get_db)):
    """
    è°ƒè¯•æ–‡ä»¶è·¯å¾„æŸ¥æ‰¾è¿‡ç¨‹
    """
    try:
        logger.info(f"Debug: Looking for file: {filename}")
        
        # æ£€æŸ¥å¯èƒ½çš„å­˜å‚¨ä½ç½®
        possible_locations = [
            Path("/tmp/pkb_uploads") / filename,
            Path("/app/uploads") / filename,
            Path("/uploads") / filename,
            Path("/data/uploads") / filename,
            Path("/var/uploads") / filename,
        ]
        
        location_status = {}
        for location in possible_locations:
            location_status[str(location)] = {
                "exists": location.exists(),
                "is_file": location.is_file() if location.exists() else False,
                "size": location.stat().st_size if location.exists() and location.is_file() else None
            }
        
        # æ£€æŸ¥æ•°æ®åº“è®°å½•
        content = db.query(Content).filter(
            Content.source_uri == f"webui://{filename}"
        ).first()
        
        db_info = None
        if content:
            db_info = {
                "id": str(content.id),
                "title": content.title,
                "source_uri": content.source_uri,
                "modality": content.modality,
                "meta_file_path": content.meta.get('file_path') if content.meta else None,
                "created_at": content.created_at.isoformat() if content.created_at else None
            }
            
            # æ£€æŸ¥metaä¸­çš„æ–‡ä»¶è·¯å¾„
            if content.meta and content.meta.get('file_path'):
                meta_path = Path(content.meta['file_path'])
                db_info["meta_path_exists"] = meta_path.exists()
                db_info["meta_path_is_file"] = meta_path.is_file() if meta_path.exists() else False
        
        return {
            "filename": filename,
            "possible_locations": location_status,
            "database_record": db_info,
            "thumbnail_dir_exists": THUMBNAIL_DIR.exists(),
            "thumbnail_dir_path": str(THUMBNAIL_DIR)
        }
        
    except Exception as e:
        logger.error(f"Debug error for {filename}: {e}")
        return {"error": str(e)}

@router.get("/list-uploads")
async def list_uploaded_files():
    """
    åˆ—å‡ºæ‰€æœ‰ä¸Šä¼ ç›®å½•ä¸­çš„æ–‡ä»¶
    """
    try:
        result = {}
        search_dirs = [
            Path("/tmp/pkb_uploads"), 
            Path("/app/uploads"), 
            Path("/uploads"), 
            Path("/data/uploads"), 
            Path("/var/uploads")
        ]
        
        for base_dir in search_dirs:
            dir_info = {
                "exists": base_dir.exists(),
                "files": []
            }
            
            if base_dir.exists():
                try:
                    all_files = list(base_dir.rglob("*"))
                    for file_path in all_files:
                        if file_path.is_file():
                            dir_info["files"].append({
                                "name": file_path.name,
                                "path": str(file_path),
                                "size": file_path.stat().st_size,
                                "modified": file_path.stat().st_mtime
                            })
                except Exception as e:
                    dir_info["error"] = str(e)
            
            result[str(base_dir)] = dir_info
        
        return result
        
    except Exception as e:
        return {"error": str(e)}

@router.get("/list-database-files")
async def list_database_files(db: Session = Depends(get_db)):
    """
    åˆ—å‡ºæ•°æ®åº“ä¸­çš„æ‰€æœ‰æ–‡ä»¶è®°å½•
    """
    try:
        contents = db.query(Content).filter(
            Content.source_uri.like("webui://%")
        ).limit(20).all()
        
        result = []
        for content in contents:
            file_info = {
                "id": str(content.id),
                "title": content.title,
                "source_uri": content.source_uri,
                "modality": content.modality,
                "created_at": content.created_at.isoformat() if content.created_at else None,
                "meta_file_path": content.meta.get('file_path') if content.meta else None,
                "meta_keys": list(content.meta.keys()) if content.meta else []
            }
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if content.meta and content.meta.get('file_path'):
                file_path = Path(content.meta['file_path'])
                file_info["file_exists"] = file_path.exists()
                file_info["file_size"] = file_path.stat().st_size if file_path.exists() else None
            
            result.append(file_info)
        
        return {
            "total_webui_files": len(result),
            "files": result
        }
        
    except Exception as e:
        return {"error": str(e)}

@router.post("/migrate-storage")
async def migrate_file_storage(db: Session = Depends(get_db)):
    """
    è¿ç§»æ–‡ä»¶å­˜å‚¨ï¼šå°†ä¸´æ—¶ç›®å½•çš„æ–‡ä»¶è·¯å¾„æ›´æ–°ä¸ºæŒä¹…åŒ–ç›®å½•
    æ³¨æ„ï¼šè¿™ä¸ä¼šç§»åŠ¨å®é™…æ–‡ä»¶ï¼Œåªæ›´æ–°æ•°æ®åº“è®°å½•
    """
    try:
        # æŸ¥æ‰¾æ‰€æœ‰WebUIä¸Šä¼ çš„æ–‡ä»¶
        contents = db.query(Content).filter(
            Content.source_uri.like("webui://%")
        ).all()
        
        updated_count = 0
        for content in contents:
            if content.meta and content.meta.get('file_path'):
                old_path = content.meta['file_path']
                
                # å¦‚æœæ˜¯ä¸´æ—¶ç›®å½•è·¯å¾„ï¼Œæ›´æ–°ä¸ºæŒä¹…åŒ–ç›®å½•
                if '/tmp/pkb_uploads/' in old_path:
                    # æå–æ–‡ä»¶å
                    file_name = Path(old_path).name
                    new_path = f"/app/uploads/{file_name}"
                    
                    # æ›´æ–°metaä¸­çš„file_path
                    content.meta['file_path'] = new_path
                    updated_count += 1
        
        # æäº¤æ›´æ”¹
        db.commit()
        
        return {
            "success": True,
            "message": f"Updated {updated_count} file records",
            "updated_count": updated_count
        }
        
    except Exception as e:
        db.rollback()
        return {"error": str(e)}

@router.post("/reset-database")
async def reset_database(confirm: bool = False, db: Session = Depends(get_db)):
    """
    é‡ç½®æ•°æ®åº“ï¼šåˆ é™¤æ‰€æœ‰WebUIä¸Šä¼ çš„æ–‡ä»¶è®°å½•
    è­¦å‘Šï¼šè¿™ä¼šåˆ é™¤æ‰€æœ‰æ•°æ®ï¼
    """
    if not confirm:
        return {
            "error": "è¯·æ·»åŠ  confirm=true å‚æ•°æ¥ç¡®è®¤åˆ é™¤æ“ä½œ",
            "warning": "è¿™å°†åˆ é™¤æ‰€æœ‰WebUIä¸Šä¼ çš„æ–‡ä»¶è®°å½•ï¼"
        }
    
    try:
        # ç»Ÿè®¡è¦åˆ é™¤çš„è®°å½•
        webui_contents = db.query(Content).filter(
            Content.source_uri.like("webui://%")
        ).all()
        
        content_count = len(webui_contents)
        chunk_count = 0
        category_count = 0
        
        # åˆ é™¤ç›¸å…³çš„chunkså’Œåˆ†ç±»å…³è”
        for content in webui_contents:
            # åˆ é™¤chunks
            chunks = db.query(Chunk).filter(Chunk.content_id == content.id).all()
            chunk_count += len(chunks)
            for chunk in chunks:
                db.delete(chunk)
            
            # åˆ é™¤åˆ†ç±»å…³è”
            categories = db.query(ContentCategory).filter(ContentCategory.content_id == content.id).all()
            category_count += len(categories)
            for category in categories:
                db.delete(category)
            
            # åˆ é™¤content
            db.delete(content)
        
        # æäº¤åˆ é™¤
        db.commit()
        
        return {
            "success": True,
            "message": "æ•°æ®åº“é‡ç½®å®Œæˆ",
            "deleted": {
                "contents": content_count,
                "chunks": chunk_count,
                "category_associations": category_count
            }
        }
        
    except Exception as e:
        db.rollback()
        return {"error": str(e)}

@router.post("/cleanup-storage")
async def cleanup_storage_directories():
    """
    æ¸…ç†å­˜å‚¨ç›®å½•ï¼šåˆ é™¤ä¸Šä¼ ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    """
    try:
        cleanup_results = {}
        
        # è¦æ¸…ç†çš„ç›®å½•
        directories_to_clean = [
            Path("/tmp/pkb_uploads"),
            Path("/app/uploads"),
            Path("/tmp/pkb_thumbnails")  # ä¹Ÿæ¸…ç†ç¼©ç•¥å›¾
        ]
        
        for directory in directories_to_clean:
            result = {
                "exists": directory.exists(),
                "files_deleted": 0,
                "errors": []
            }
            
            if directory.exists():
                try:
                    # åˆ é™¤ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
                    for file_path in directory.rglob("*"):
                        if file_path.is_file():
                            try:
                                file_path.unlink()
                                result["files_deleted"] += 1
                            except Exception as e:
                                result["errors"].append(f"Failed to delete {file_path}: {e}")
                    
                    # å¯é€‰ï¼šåˆ é™¤ç©ºç›®å½•
                    if result["files_deleted"] > 0 and not result["errors"]:
                        try:
                            directory.rmdir()
                        except:
                            pass  # ç›®å½•å¯èƒ½ä¸ä¸ºç©ºæˆ–æœ‰æƒé™é—®é¢˜ï¼Œå¿½ç•¥
                            
                except Exception as e:
                    result["errors"].append(f"Failed to access directory: {e}")
            
            cleanup_results[str(directory)] = result
        
        return {
            "success": True,
            "message": "å­˜å‚¨ç›®å½•æ¸…ç†å®Œæˆ",
            "results": cleanup_results
        }
        
    except Exception as e:
        return {"error": str(e)}

@router.get("/check-upload-config")
async def check_upload_config():
    """
    æ£€æŸ¥å½“å‰çš„ä¸Šä¼ é…ç½®
    """
    try:
        # æ£€æŸ¥å„ä¸ªå¯èƒ½çš„ä¸Šä¼ ç›®å½•
        test_dirs = [
            Path("/app/uploads"),
            Path("/tmp/pkb_uploads"),
            Path("/data/uploads"),
            Path("/uploads")
        ]
        
        dir_status = {}
        for test_dir in test_dirs:
            dir_status[str(test_dir)] = {
                "exists": test_dir.exists(),
                "writable": test_dir.exists() and os.access(test_dir, os.W_OK),
                "files_count": len(list(test_dir.rglob("*"))) if test_dir.exists() else 0
            }
        
        return {
            "upload_directories": dir_status,
            "recommended_dir": "/app/uploads",
            "current_time": time.time(),
            "message": "Check if ingest.py changes were deployed"
        }
        
    except Exception as e:
        return {"error": str(e)}
