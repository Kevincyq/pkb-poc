"""
é—®ç­”æœåŠ¡ - åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)
ä½¿ç”¨ Turing å¹³å° API è°ƒç”¨ OpenAI æ¨¡å‹
"""
import os
import time
import uuid
from typing import List, Dict, Optional, Tuple
from sqlalchemy.orm import Session
from app.models import QAHistory, Content, Chunk
from app.services.search_service import SearchService
import logging

# å¯¼å…¥æ–°ç‰ˆæœ¬ OpenAI å®¢æˆ·ç«¯
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OpenAI = None
    OPENAI_AVAILABLE = False

logger = logging.getLogger(__name__)

class QAService:
    def __init__(self, db: Session):
        self.db = db
        self.search_service = SearchService(db)
        
        # æ£€æŸ¥ OpenAI åº“å¯ç”¨æ€§
        if not OPENAI_AVAILABLE:
            logger.error("OpenAI library not available. Install with: pip install openai>=1.0.0")
            self.openai_enabled = False
            self.openai_client = None
            return
        
        # é…ç½® Turing API
        self.turing_api_key = os.getenv("TURING_API_KEY")
        self.turing_api_base = os.getenv("TURING_API_BASE")
        self.qa_model = os.getenv("QA_MODEL", "turing/gpt-4o-mini")
        
        # æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
        if not self.turing_api_key or not self.turing_api_base:
            logger.error("Turing API configuration missing. Please set TURING_API_KEY and TURING_API_BASE")
            self.openai_enabled = False
            self.openai_client = None
            return
        
        try:
            # åˆ›å»º Turing API å®¢æˆ·ç«¯
            self.openai_client = OpenAI(
                api_key=self.turing_api_key,
                base_url=self.turing_api_base
            )
            self.openai_enabled = True
            logger.info(f"Turing API client initialized successfully with model: {self.qa_model}")
        except Exception as e:
            logger.error(f"Failed to initialize Turing API client: {e}")
            self.openai_enabled = False
            self.openai_client = None
    
    def is_enabled(self) -> bool:
        """æ£€æŸ¥ QA æœåŠ¡æ˜¯å¦å¯ç”¨"""
        return self.openai_enabled and self.openai_client is not None
    
    def test_connection(self) -> Dict:
        """æµ‹è¯• Turing API è¿æ¥"""
        if not self.openai_client:
            return {
                "status": "error",
                "message": "Turing API å®¢æˆ·ç«¯æœªé…ç½®"
            }
        
        try:
            # å‘é€æµ‹è¯•è¯·æ±‚
            response = self.openai_client.chat.completions.create(
                model=self.qa_model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç¤¼è²Œçš„ AI åŠ©æ‰‹ï¼Œä½ å« 'å°T'ã€‚"},
                    {"role": "user", "content": "è¯·ç®€å•å›åº”ä¸€ä¸‹ï¼Œç¡®è®¤è¿æ¥æ­£å¸¸"}
                ],
                max_tokens=20,
                temperature=0.7
            )
            
            return {
                "status": "success",
                "message": "Turing API è¿æ¥æ­£å¸¸",
                "model": self.qa_model,
                "test_response": response.choices[0].message.content
            }
        except Exception as e:
            logger.error(f"Turing API connection test failed: {e}")
            return {
                "status": "error",
                "message": f"Turing API è¿æ¥å¤±è´¥: {str(e)}"
            }
    
    def ask(
        self, 
        question: str, 
        session_id: Optional[str] = None,
        context_limit: int = 3000,
        model: Optional[str] = None,
        search_type: str = "hybrid",
        category_filter: Optional[str] = None,
        collection_id: Optional[str] = None
    ) -> Dict:
        """
        åŸºäºçŸ¥è¯†åº“çš„é—®ç­”
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            session_id: ä¼šè¯IDï¼ˆç”¨äºä¸Šä¸‹æ–‡ï¼‰
            context_limit: ä¸Šä¸‹æ–‡å­—ç¬¦é™åˆ¶
            model: ä½¿ç”¨çš„LLMæ¨¡å‹
            search_type: æœç´¢ç±»å‹
            category_filter: åˆ†ç±»ç­›é€‰ï¼ˆåˆ†ç±»IDæˆ–åç§°ï¼‰
            collection_id: åˆé›†èŒƒå›´é™åˆ¶ï¼ˆåˆé›†IDï¼‰
        
        Returns:
            é—®ç­”ç»“æœå­—å…¸
        """
        if not self.openai_enabled:
            return self._fallback_answer(question)
        
        # ä½¿ç”¨é…ç½®çš„æ¨¡å‹æˆ–ä¼ å…¥çš„æ¨¡å‹
        if model is None:
            model = self.qa_model
        
        try:
            # 1. æœç´¢ç›¸å…³æ–‡æ¡£
            # æ„å»ºæœç´¢è¿‡æ»¤æ¡ä»¶
            filters = {}
            if category_filter:
                filters["category"] = category_filter
            
            # å¦‚æœæŒ‡å®šäº†åˆé›†èŒƒå›´ï¼Œé™åˆ¶æœç´¢èŒƒå›´
            if collection_id:
                filters["collection_id"] = collection_id
            
            search_results = self.search_service.search(
                query=question, 
                top_k=5, 
                search_type=search_type,
                filters=filters if filters else None
            )
            
            if not search_results["results"]:
                return {
                    "question": question,
                    "answer": "æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚",
                    "sources": [],
                    "formatted_sources": "",
                    "confidence": 0.0,
                    "session_id": session_id
                }
            
            # 2. æ„å»ºä¸Šä¸‹æ–‡
            context, sources = self._build_context(search_results["results"], context_limit)
            
            # 3. è·å–å†å²å¯¹è¯ï¼ˆå¦‚æœæœ‰ä¼šè¯IDï¼‰
            conversation_history = self._get_conversation_history(session_id) if session_id else []
            
            # 4. è¿‡æ»¤é«˜è´¨é‡æ¥æº
            filtered_sources = self._filter_high_quality_sources(sources, question)
            
            # å¦‚æœè¿‡æ»¤åæ²¡æœ‰é«˜è´¨é‡æ¥æºï¼Œä½†åŸå§‹æœç´¢æœ‰ç»“æœï¼Œç»™å‡ºæç¤º
            if not filtered_sources and sources:
                logger.warning(f"No high-quality sources found for question: {question}")
                return {
                    "question": question,
                    "answer": "æŠ±æ­‰ï¼Œè™½ç„¶æ‰¾åˆ°äº†ä¸€äº›ç›¸å…³æ–‡æ¡£ï¼Œä½†ç›¸å…³åº¦è¾ƒä½ï¼Œæ— æ³•ä¸ºæ‚¨æä¾›å‡†ç¡®çš„ç­”æ¡ˆã€‚å»ºè®®æ‚¨å°è¯•ä½¿ç”¨æ›´å…·ä½“çš„å…³é”®è¯é‡æ–°æé—®ã€‚",
                    "sources": [],
                    "formatted_sources": "",
                    "confidence": 0.1,
                    "session_id": session_id
                }
            
            # 5. ç”Ÿæˆæ ¼å¼åŒ–çš„æ–‡æ¡£æ¥æºä¿¡æ¯
            formatted_sources = self._format_sources_for_display(filtered_sources)
            
            # 6. ç”Ÿæˆå›ç­”
            answer_data = self._generate_answer(question, context, conversation_history, model, category_filter, formatted_sources)
            
            # 7. ä¿å­˜é—®ç­”å†å²
            qa_record = self._save_qa_history(
                question=question,
                answer=answer_data["answer"],
                sources=filtered_sources,
                session_id=session_id,
                model_used=model,
                tokens_used=answer_data.get("tokens_used", 0),
                confidence=answer_data.get("confidence", 0.0)
            )
            
            return {
                "question": question,
                "answer": answer_data["answer"],
                "sources": filtered_sources,  # è¿”å›è¿‡æ»¤åçš„æ¥æºï¼ˆåŸå§‹æ•°æ®ï¼‰
                "formatted_sources": formatted_sources,  # æ ¼å¼åŒ–çš„æ¥æºä¿¡æ¯
                "confidence": answer_data.get("confidence", 0.0),
                "model_used": model,
                "search_type": search_type,
                "category_filter": category_filter,
                "session_id": session_id,
                "qa_id": str(qa_record.id),
                "search_results_count": len(search_results["results"])
            }
            
        except Exception as e:
            logger.error(f"QA service error: {e}")
            return {
                "question": question,
                "answer": f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™ï¼š{str(e)}",
                "sources": [],
                "confidence": 0.0,
                "session_id": session_id,
                "error": str(e)
            }
    
    def _build_context(self, search_results: List[Dict], limit: int) -> Tuple[str, List[Dict]]:
        """æ„å»ºä¸Šä¸‹æ–‡å’Œæ¥æºä¿¡æ¯"""
        context_parts = []
        sources = []
        current_length = 0
        
        for i, result in enumerate(search_results, 1):
            source_info = f"[æ–‡æ¡£{i}: {result['title']}]"
            content = f"{source_info}\\n{result['text']}\\n"
            
            if current_length + len(content) > limit:
                break
            
            context_parts.append(content)
            current_length += len(content)
            
            # æ·»åŠ æ¥æºä¿¡æ¯
            sources.append({
                "title": result["title"],
                "text": result["text"][:200] + "..." if len(result["text"]) > 200 else result["text"],
                "source_uri": result["source_uri"],
                "score": result["score"],
                "content_id": result["content_id"],
                "category_name": result.get("category_name"),
                "modality": result.get("modality", "text"),
                "confidence_percentage": round(result["score"] * 100, 0) if result["score"] else 0
            })
        
        context = "\\n".join(context_parts)
        return context, sources
    
    def _filter_high_quality_sources(self, sources: List[Dict], question: str) -> List[Dict]:
        """è¿‡æ»¤é«˜è´¨é‡çš„æ–‡æ¡£æ¥æº"""
        if not sources:
            return []
        
        # è®¾ç½®ç›¸å…³åº¦é˜ˆå€¼
        min_score_threshold = 0.15  # æœ€ä½ç›¸å…³åº¦é˜ˆå€¼ï¼ˆé™ä½åˆ°15%ï¼‰
        high_score_threshold = 0.5   # é«˜ç›¸å…³åº¦é˜ˆå€¼ï¼ˆé™ä½åˆ°50%ï¼‰
        
        # åˆ†æé—®é¢˜å…³é”®è¯
        question_lower = question.lower()
        question_keywords = self._extract_question_keywords(question_lower)
        
        logger.info(f"Question: {question}")
        logger.info(f"Extracted keywords: {question_keywords}")
        logger.info(f"Original sources count: {len(sources)}")
        
        filtered_sources = []
        
        for source in sources:
            score = source.get("score", 0)
            title = source.get("title", "").lower()
            text = source.get("text", "").lower()
            
            # åŸºç¡€ç›¸å…³åº¦è¿‡æ»¤
            if score < min_score_threshold:
                continue
            
            # å…³é”®è¯åŒ¹é…æ£€æŸ¥
            keyword_matches = 0
            for keyword in question_keywords:
                if keyword in title or keyword in text:
                    keyword_matches += 1
            
            # è®¡ç®—ç»¼åˆç›¸å…³åº¦
            keyword_ratio = keyword_matches / len(question_keywords) if question_keywords else 0
            combined_score = score * 0.7 + keyword_ratio * 0.3
            
            # æ›´æ–°ç›¸å…³åº¦ç™¾åˆ†æ¯”
            source["confidence_percentage"] = round(combined_score * 100, 0)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå›¾ç‰‡æœç´¢
            is_image_search = any(keyword in question_lower for keyword in ['ç…§ç‰‡', 'å›¾ç‰‡', 'å›¾åƒ', 'æ‹ç…§', 'æ‘„å½±'])
            
            # é«˜è´¨é‡æ¥æºï¼šé«˜ç›¸å…³åº¦æˆ–å…³é”®è¯åŒ¹é…åº¦é«˜
            if combined_score >= high_score_threshold or keyword_ratio >= 0.4:
                filtered_sources.append(source)
            # ä¸­ç­‰è´¨é‡æ¥æºï¼šå¦‚æœå·²æœ‰æ¥æºå°‘äº3ä¸ªï¼Œå¯ä»¥åŒ…å«
            elif len(filtered_sources) < 3 and combined_score >= min_score_threshold:
                filtered_sources.append(source)
            # å›¾ç‰‡æœç´¢ç‰¹æ®Šå¤„ç†ï¼šæ›´å®½æ¾çš„é˜ˆå€¼ï¼Œå› ä¸ºåŒç±»å›¾ç‰‡éƒ½æœ‰ä»·å€¼
            elif is_image_search and len(filtered_sources) < 3 and score >= 0.1:
                filtered_sources.append(source)
            # ä½è´¨é‡ä½†ä»æœ‰ä¸€å®šç›¸å…³æ€§çš„æ¥æºï¼šå¦‚æœæ²¡æœ‰å…¶ä»–æ¥æºï¼Œè‡³å°‘ä¿ç•™ä¸€ä¸ª
            elif len(filtered_sources) == 0 and score >= 0.1:
                filtered_sources.append(source)
        
        # æŒ‰ç»¼åˆç›¸å…³åº¦æ’åº
        filtered_sources.sort(key=lambda x: x.get("confidence_percentage", 0), reverse=True)
        
        logger.info(f"Filtered sources count: {len(filtered_sources)}")
        for i, source in enumerate(filtered_sources):
            logger.info(f"Source {i+1}: {source.get('title', 'Unknown')} - {source.get('confidence_percentage', 0)}%")
        
        # æœ€å¤šè¿”å›3ä¸ªï¼Œä½†éœ€è¦æ™ºèƒ½åˆ¤æ–­æ˜¯å¦è¿‡æ»¤
        max_sources = 3
        if len(filtered_sources) > 1:
            # æ£€æŸ¥æ˜¯å¦ä¸ºå›¾ç‰‡æœç´¢ï¼ˆæ ¹æ®é—®é¢˜å†…å®¹åˆ¤æ–­ï¼‰
            is_image_search = any(keyword in question.lower() for keyword in ['ç…§ç‰‡', 'å›¾ç‰‡', 'å›¾åƒ', 'æ‹ç…§', 'æ‘„å½±'])
            
            # æ£€æŸ¥ç¬¬äºŒä¸ªæ¥æºçš„è´¨é‡ï¼Œå¦‚æœç›¸å…³åº¦å·®è·å¤ªå¤§ï¼Œåªè¿”å›ç¬¬ä¸€ä¸ª
            first_score = filtered_sources[0].get("confidence_percentage", 0)
            second_score = filtered_sources[1].get("confidence_percentage", 0)
            
            # å›¾ç‰‡æœç´¢ä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼ï¼Œå› ä¸ºåŒç±»å›¾ç‰‡ç›¸å…³åº¦é€šå¸¸æ¯”è¾ƒæ¥è¿‘
            threshold = 30 if is_image_search else 50
            
            if first_score - second_score > threshold:
                logger.info(f"Filtering out low-quality sources (threshold={threshold}%): first={first_score}%, second={second_score}%")
                return filtered_sources[:1]
        
        final_sources = filtered_sources[:max_sources]
        logger.info(f"Final sources count: {len(final_sources)}")
        
        return final_sources
    
    def _extract_question_keywords(self, question: str) -> List[str]:
        """æå–é—®é¢˜ä¸­çš„å…³é”®è¯"""
        # ç§»é™¤å¸¸è§çš„ç–‘é—®è¯å’Œåœç”¨è¯
        stop_words = {
            "ä»€ä¹ˆ", "å“ªäº›", "å¦‚ä½•", "æ€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "è°", "å“ªä¸ª", "å“ªé‡Œ", "ä»€ä¹ˆæ—¶å€™", 
            "æœ‰", "æ˜¯", "çš„", "äº†", "åœ¨", "å’Œ", "ä¸", "æˆ–", "ä½†æ˜¯", "ç„¶è€Œ", "å› ä¸º",
            "æ‰€ä»¥", "è¿™ä¸ª", "é‚£ä¸ª", "è¿™äº›", "é‚£äº›", "æˆ‘", "ä½ ", "ä»–", "å¥¹", "å®ƒä»¬",
            "ä»»åŠ¡", "é¡¹ç›®", "å·¥ä½œ", "ä¼šè®®", "é—®é¢˜"  # æ·»åŠ ä¸€äº›é€šç”¨è¯
        }
        
        # ç®€å•åˆ†è¯ï¼ˆæŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹åˆ†å‰²ï¼‰
        import re
        words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+', question)
        
        # è¿‡æ»¤åœç”¨è¯ï¼Œä½†ä¿ç•™äººåï¼ˆé€šå¸¸2-4ä¸ªå­—ç¬¦ï¼‰
        keywords = []
        for word in words:
            if len(word) >= 2 and word not in stop_words:
                keywords.append(word)
            # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ˜¯å¯èƒ½çš„äººåï¼ˆ2-4ä¸ªå­—ç¬¦çš„ä¸­æ–‡ï¼‰ï¼Œå³ä½¿åœ¨åœç”¨è¯ä¸­ä¹Ÿä¿ç•™
            elif len(word) >= 2 and len(word) <= 4 and re.match(r'^[\u4e00-\u9fff]+$', word):
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å¸¸è§å§“æ°
                common_surnames = {'å¼ ', 'ç‹', 'æ', 'åˆ˜', 'é™ˆ', 'æ¨', 'èµµ', 'é»„', 'å‘¨', 'å´', 'å¾', 'å­™', 'èƒ¡', 'æœ±', 'é«˜', 'æ—', 'ä½•', 'éƒ­', 'é©¬', 'ç½—'}
                if any(word.startswith(surname) for surname in common_surnames):
                    keywords.append(word)
        
        return keywords
    
    def _format_sources_for_display(self, sources: List[Dict]) -> str:
        """æ ¼å¼åŒ–æ–‡æ¡£æ¥æºä¿¡æ¯ä¸ºMarkdownæ ¼å¼"""
        if not sources:
            return ""
        
        formatted_lines = ["### ğŸ”— ç›¸å…³æ–‡æ¡£"]
        
        for i, source in enumerate(sources, 1):
            title = source.get("title", "æœªçŸ¥æ–‡æ¡£")
            category_name = source.get("category_name", "")
            confidence = source.get("confidence_percentage", 0)
            content_id = source.get("content_id", "")
            
            # ç”Ÿæˆå†…éƒ¨é“¾æ¥URLï¼ˆå‰ç«¯ä¼šå¤„ç†è¿™ä¸ªé“¾æ¥ï¼‰
            if category_name:
                link_url = f"#/collection/{category_name}?highlight={content_id}"
            else:
                link_url = f"#/document/{content_id}"
            
            # æ ¼å¼åŒ–æ¯ä¸ªæ–‡æ¡£æ¡ç›®
            formatted_lines.append(f"{i}. [{title}]({link_url}) - ç›¸å…³åº¦ï¼š{confidence}%")
        
        return "\n".join(formatted_lines)
    
    def _get_conversation_history(self, session_id: str, limit: int = 5) -> List[Dict]:
        """è·å–å¯¹è¯å†å²"""
        try:
            history = self.db.query(QAHistory).filter(
                QAHistory.session_id == session_id
            ).order_by(QAHistory.created_at.desc()).limit(limit).all()
            
            return [
                {
                    "question": h.question,
                    "answer": h.answer,
                    "created_at": h.created_at.isoformat()
                }
                for h in reversed(history)  # æŒ‰æ—¶é—´æ­£åº
            ]
        except Exception as e:
            logger.error(f"Error getting conversation history: {e}")
            return []
    
    def _build_conversation_messages(
        self, 
        question: str, 
        context: str, 
        conversation_history: List[Dict],
        category_filter: Optional[str] = None,
        formatted_sources: str = ""
    ) -> List[Dict]:
        """æ„å»ºåŒ…å«å¤šè½®å¯¹è¯å†å²çš„æ¶ˆæ¯åˆ—è¡¨"""
        messages = []
        
        # 1. ç³»ç»Ÿæç¤º
        system_prompt = self._build_system_prompt(category_filter)
        messages.append({"role": "system", "content": system_prompt})
        
        # 2. æ·»åŠ å¯¹è¯å†å²ï¼ˆæœ€è¿‘çš„å‡ è½®ï¼‰
        for hist in conversation_history[-6:]:  # ä¿ç•™æœ€è¿‘6è½®å¯¹è¯
            messages.append({"role": "user", "content": hist["question"]})
            messages.append({"role": "assistant", "content": hist["answer"]})
        
        # 3. å½“å‰é—®é¢˜å’Œä¸Šä¸‹æ–‡
        current_message = self._build_user_message(question, context, [], formatted_sources)
        messages.append({"role": "user", "content": current_message})
        
        return messages
    
    def _generate_answer(
        self, 
        question: str, 
        context: str, 
        conversation_history: List[Dict],
        model: str,
        category_filter: Optional[str] = None,
        formatted_sources: str = ""
    ) -> Dict:
        """ç”Ÿæˆå›ç­” - ä½¿ç”¨ Turing API å’Œå¤šè½®å¯¹è¯"""
        if not self.openai_client:
            return {
                "answer": "Turing API å®¢æˆ·ç«¯æœªé…ç½®ï¼Œæ— æ³•ç”Ÿæˆå›ç­”ã€‚",
                "confidence": 0.0,
                "tokens_used": 0
            }
        
        try:
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«å¤šè½®å¯¹è¯å†å²
            messages = self._build_conversation_messages(question, context, conversation_history, category_filter, formatted_sources)
            
            logger.info(f"Generating answer using model: {model}")
            logger.debug(f"Message count: {len(messages)}")
            
            # è°ƒç”¨ Turing API
            response = self.openai_client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.7,
                max_tokens=1000,
                top_p=0.9
            )
            
            answer = response.choices[0].message.content
            tokens_used = response.usage.total_tokens
            
            logger.info(f"Answer generated successfully, tokens used: {tokens_used}")
            
            # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºç­”æ¡ˆé•¿åº¦å’Œæœç´¢ç»“æœç›¸å…³æ€§ï¼‰
            confidence = self._calculate_confidence(answer, context)
            
            return {
                "answer": answer,
                "confidence": confidence,
                "tokens_used": tokens_used
            }
            
        except Exception as e:
            logger.error(f"Error generating answer with Turing API: {e}")
            return {
                "answer": f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™ï¼š{str(e)}",
                "confidence": 0.0,
                "tokens_used": 0
            }
    
    def _build_system_prompt(self, category_filter: Optional[str] = None) -> str:
        """æ„å»ºç³»ç»Ÿæç¤º"""
        base_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸ªäººçŸ¥è¯†åº“åŠ©æ‰‹ã€‚è¯·åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

å›ç­”æ ¼å¼è¦æ±‚ï¼š
è¯·ä½¿ç”¨ä»¥ä¸‹ç»“æ„åŒ–çš„Markdownæ ¼å¼å›ç­”ï¼š

## ğŸ“‹ å…³äºæ‚¨çš„é—®é¢˜

### ğŸ’¡ æ ¸å¿ƒç­”æ¡ˆ
[åœ¨è¿™é‡Œæä¾›ç®€æ´æ˜ç¡®çš„æ ¸å¿ƒç­”æ¡ˆ]

### ğŸ“š è¯¦ç»†è¯´æ˜
- **è¦ç‚¹1**ï¼šå…·ä½“è¯´æ˜å†…å®¹
- **è¦ç‚¹2**ï¼šå…·ä½“è¯´æ˜å†…å®¹
- **è¦ç‚¹3**ï¼šå…·ä½“è¯´æ˜å†…å®¹

### ğŸ’­ è¡¥å……ä¿¡æ¯
[å¦‚æœ‰éœ€è¦ï¼Œæä¾›è¡¥å……è¯´æ˜æˆ–ç›¸å…³èƒŒæ™¯ä¿¡æ¯]

è§„åˆ™ï¼š
1. ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°Markdownæ ¼å¼è¾“å‡º
2. åªåŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”ï¼Œä¸è¦æ·»åŠ æ–‡æ¡£ä¸­æ²¡æœ‰çš„ä¿¡æ¯
3. å¦‚æœæ–‡æ¡£ä¸­ä¿¡æ¯ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·åœ¨"æ ¸å¿ƒç­”æ¡ˆ"éƒ¨åˆ†è¯šå®è¯´æ˜
4. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ã€æœ‰æ¡ç†
5. å¯ä»¥åœ¨è¯¦ç»†è¯´æ˜ä¸­å¼•ç”¨å…·ä½“çš„æ–‡æ¡£å†…å®¹
6. ä½¿ç”¨ä¸­æ–‡å›ç­”"""

        if category_filter:
            base_prompt += f"""
7. å½“å‰æŸ¥è¯¢é™å®šåœ¨"{category_filter}"åˆ†ç±»èŒƒå›´å†…ï¼Œè¯·åœ¨å›ç­”æ—¶è€ƒè™‘è¿™ä¸ªä¸Šä¸‹æ–‡"""

        return base_prompt
    
    def _build_user_message(self, question: str, context: str, conversation_history: List[Dict], formatted_sources: str = "") -> str:
        """æ„å»ºç”¨æˆ·æ¶ˆæ¯"""
        message_parts = []
        
        # æ·»åŠ å¯¹è¯å†å²
        if conversation_history:
            message_parts.append("å¯¹è¯å†å²ï¼š")
            for h in conversation_history[-3:]:  # åªä¿ç•™æœ€è¿‘3è½®å¯¹è¯
                message_parts.append(f"Q: {h['question']}")
                message_parts.append(f"A: {h['answer'][:100]}...")  # æˆªæ–­å†å²å›ç­”
            message_parts.append("")
        
        # æ·»åŠ æ–‡æ¡£ä¸Šä¸‹æ–‡
        message_parts.append("ç›¸å…³æ–‡æ¡£å†…å®¹ï¼š")
        message_parts.append(context)
        message_parts.append("")
        
        # æ·»åŠ å½“å‰é—®é¢˜
        message_parts.append(f"ç”¨æˆ·é—®é¢˜ï¼š{question}")
        message_parts.append("")
        message_parts.append("è¯·åŸºäºä¸Šè¿°æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚")
        
        # å¦‚æœæœ‰æ ¼å¼åŒ–çš„æ¥æºä¿¡æ¯ï¼Œæç¤ºAIåœ¨å›å¤æœ«å°¾æ·»åŠ 
        if formatted_sources:
            message_parts.append("")
            message_parts.append("æ³¨æ„ï¼šè¯·åœ¨ä½ çš„å›å¤æœ«å°¾æ·»åŠ ä»¥ä¸‹æ–‡æ¡£æ¥æºä¿¡æ¯ï¼š")
            message_parts.append(formatted_sources)
        
        return "\\n".join(message_parts)
    
    def _calculate_confidence(self, answer: str, context: str) -> float:
        """è®¡ç®—å›ç­”ç½®ä¿¡åº¦"""
        try:
            # ç®€å•çš„ç½®ä¿¡åº¦è®¡ç®—é€»è¾‘
            if "æŠ±æ­‰" in answer or "ä¸çŸ¥é“" in answer or "æ²¡æœ‰æ‰¾åˆ°" in answer:
                return 0.2
            elif len(answer) < 50:
                return 0.5
            elif len(context) > 1000:
                return 0.9
            else:
                return 0.7
        except:
            return 0.5
    
    def _save_qa_history(
        self, 
        question: str, 
        answer: str, 
        sources: List[Dict],
        session_id: Optional[str],
        model_used: str,
        tokens_used: int,
        confidence: float
    ) -> QAHistory:
        """ä¿å­˜é—®ç­”å†å²"""
        try:
            qa_record = QAHistory(
                session_id=session_id,
                question=question,
                answer=answer,
                sources=[{"content_id": s["content_id"], "title": s["title"]} for s in sources],
                model_used=model_used,
                tokens_used=tokens_used,
                confidence=confidence
            )
            
            self.db.add(qa_record)
            self.db.commit()
            self.db.refresh(qa_record)
            
            return qa_record
            
        except Exception as e:
            logger.error(f"Error saving QA history: {e}")
            self.db.rollback()
            # è¿”å›ä¸€ä¸ªä¸´æ—¶å¯¹è±¡
            temp_record = QAHistory(id=uuid.uuid4())
            return temp_record
    
    def _fallback_answer(self, question: str) -> Dict:
        """å½“ OpenAI ä¸å¯ç”¨æ—¶çš„å›é€€å›ç­”"""
        return {
            "question": question,
            "answer": "æŠ±æ­‰ï¼ŒAI é—®ç­”æœåŠ¡å½“å‰ä¸å¯ç”¨ã€‚æ‚¨å¯ä»¥å°è¯•ä½¿ç”¨æœç´¢åŠŸèƒ½æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯ã€‚",
            "sources": [],
            "confidence": 0.0,
            "model_used": "fallback"
        }
    
    def get_qa_history(self, session_id: Optional[str] = None, limit: int = 20) -> List[Dict]:
        """è·å–é—®ç­”å†å²"""
        try:
            query = self.db.query(QAHistory)
            
            if session_id:
                query = query.filter(QAHistory.session_id == session_id)
            
            history = query.order_by(QAHistory.created_at.desc()).limit(limit).all()
            
            return [
                {
                    "id": str(h.id),
                    "question": h.question,
                    "answer": h.answer,
                    "confidence": h.confidence,
                    "model_used": h.model_used,
                    "created_at": h.created_at.isoformat(),
                    "sources_count": len(h.sources) if h.sources else 0
                }
                for h in history
            ]
            
        except Exception as e:
            logger.error(f"Error getting QA history: {e}")
            return []
    
    def update_feedback(self, qa_id: str, feedback: str) -> bool:
        """æ›´æ–°é—®ç­”åé¦ˆ"""
        try:
            qa_record = self.db.query(QAHistory).filter(QAHistory.id == qa_id).first()
            if qa_record:
                qa_record.feedback = feedback
                self.db.commit()
                return True
            return False
        except Exception as e:
            logger.error(f"Error updating feedback: {e}")
            return False
