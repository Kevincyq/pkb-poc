#!/usr/bin/env python3
"""
æµ‹è¯•æœç´¢å»é‡å’Œç›¸å…³æ€§æ”¹è¿›
"""
import requests
import json
from urllib.parse import urlencode

def test_search_deduplication():
    """æµ‹è¯•æœç´¢å»é‡åŠŸèƒ½"""
    base_url = "https://pkb.kmchat.cloud/api/search/"
    
    test_cases = [
        {
            "name": "è¯­ä¹‰æœç´¢ - æœºå™¨å­¦ä¹ ",
            "params": {"q": "æœºå™¨å­¦ä¹ çš„å‘å±•å‰æ™¯", "search_type": "semantic"},
            "expected_improvement": "åªæ˜¾ç¤ºç›¸å…³æ–‡æ¡£ï¼Œè¿‡æ»¤æ‰ppp.txtç­‰ä¸ç›¸å…³å†…å®¹"
        },
        {
            "name": "è¯­ä¹‰æœç´¢ - å±±é¡¶ç…§ç‰‡", 
            "params": {"q": "å±±é¡¶ç…§ç‰‡", "search_type": "semantic"},
            "expected_improvement": "åªæ˜¾ç¤ºå›¾ç‰‡æ–‡ä»¶ï¼Œè¿‡æ»¤æ‰.mdå’Œ.txtæ–‡æ¡£"
        },
        {
            "name": "å…³é”®è¯æœç´¢ - äººå·¥æ™ºèƒ½",
            "params": {"q": "äººå·¥æ™ºèƒ½", "search_type": "keyword"},
            "expected_improvement": "æ¯ä¸ªæ–‡æ¡£åªå‡ºç°ä¸€æ¬¡"
        },
        {
            "name": "æ··åˆæœç´¢ - æŠ€æœ¯æ–‡æ¡£",
            "params": {"q": "æŠ€æœ¯æ–‡æ¡£", "search_type": "hybrid"},
            "expected_improvement": "ç»“åˆå…³é”®è¯å’Œè¯­ä¹‰æœç´¢ï¼Œå»é‡åç»“æœ"
        }
    ]
    
    print("ğŸ” æµ‹è¯•æœç´¢å»é‡å’Œç›¸å…³æ€§æ”¹è¿›")
    print("=" * 60)
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{i}. {test_case['name']}")
        print("-" * 40)
        
        try:
            # æ„å»ºURL
            url = f"{base_url}?{urlencode(test_case['params'])}"
            print(f"è¯·æ±‚URL: {url}")
            
            # å‘é€è¯·æ±‚
            response = requests.get(url, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                results = data.get('results', [])
                
                print(f"âœ“ çŠ¶æ€ç : {response.status_code}")
                print(f"âœ“ ç»“æœæ•°é‡: {len(results)}")
                
                # æ£€æŸ¥å»é‡æ•ˆæœ
                titles = [r.get('title', '') for r in results]
                unique_titles = list(set(titles))
                duplicate_count = len(titles) - len(unique_titles)
                
                if duplicate_count == 0:
                    print("âœ… å»é‡æˆåŠŸï¼šæ²¡æœ‰é‡å¤æ–‡æ¡£")
                else:
                    print(f"âŒ ä»æœ‰é‡å¤ï¼š{duplicate_count} ä¸ªé‡å¤æ–‡æ¡£")
                    # æ˜¾ç¤ºé‡å¤çš„æ–‡æ¡£
                    from collections import Counter
                    title_counts = Counter(titles)
                    duplicates = {title: count for title, count in title_counts.items() if count > 1}
                    if duplicates:
                        print("é‡å¤æ–‡æ¡£:")
                        for title, count in duplicates.items():
                            print(f"  - {title}: {count} æ¬¡")
                
                # æ˜¾ç¤ºå‰5ä¸ªç»“æœçš„æ ‡é¢˜å’Œåˆ†æ•°
                print("å‰5ä¸ªç»“æœ:")
                for j, result in enumerate(results[:5], 1):
                    title = result.get('title', 'N/A')
                    score = result.get('score', 0)
                    modality = result.get('modality', 'N/A')
                    print(f"  {j}. {title} (åˆ†æ•°: {score:.3f}, ç±»å‹: {modality})")
                
                # æ™ºèƒ½åˆ†æç»“æœè´¨é‡
                _analyze_result_quality(test_case, results)
                
                print(f"é¢„æœŸæ”¹è¿›: {test_case['expected_improvement']}")
                
            else:
                print(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                print(f"å“åº”å†…å®¹: {response.text}")
                
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    
    print("\n" + "=" * 60)
    print("ğŸ¯ æµ‹è¯•å®Œæˆ")
    print("\nğŸ’¡ å¦‚æœä»æœ‰é‡å¤ç»“æœï¼Œè¯·æ£€æŸ¥:")
    print("1. åç«¯æœåŠ¡æ˜¯å¦å·²é‡å¯å¹¶åŠ è½½äº†æ–°ä»£ç ")
    print("2. æ•°æ®åº“ä¸­æ˜¯å¦å­˜åœ¨çœŸæ­£çš„é‡å¤å†…å®¹")
    print("3. ç›¸ä¼¼åº¦é˜ˆå€¼æ˜¯å¦éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´")

def _analyze_result_quality(test_case, results):
    """åˆ†ææœç´¢ç»“æœè´¨é‡"""
    query = test_case['params']['q']
    
    if "å±±é¡¶ç…§ç‰‡" in query:
        # åˆ†æå›¾ç‰‡æœç´¢ç»“æœ
        image_count = sum(1 for r in results if r.get('modality') == 'image')
        non_image_count = len(results) - image_count
        
        if non_image_count == 0:
            print("âœ… æ™ºèƒ½è¿‡æ»¤æˆåŠŸï¼šåªè¿”å›å›¾ç‰‡æ–‡ä»¶")
        else:
            print(f"âš ï¸  ä»æœ‰éå›¾ç‰‡æ–‡ä»¶ï¼š{non_image_count} ä¸ª")
            for r in results:
                if r.get('modality') != 'image':
                    print(f"   - {r.get('title')} (ç±»å‹: {r.get('modality')}, åˆ†æ•°: {r.get('score', 0):.3f})")
    
    elif "æœºå™¨å­¦ä¹ " in query:
        # åˆ†ææœºå™¨å­¦ä¹ ç›¸å…³æœç´¢
        low_score_count = sum(1 for r in results if r.get('score', 0) < 0.25)
        irrelevant_files = [r for r in results if 'ppp.txt' in r.get('title', '') or r.get('score', 0) < 0.25]
        
        if not irrelevant_files:
            print("âœ… æ™ºèƒ½è¿‡æ»¤æˆåŠŸï¼šè¿‡æ»¤æ‰ä¸ç›¸å…³å†…å®¹")
        else:
            print(f"âš ï¸  ä»æœ‰ä¸ç›¸å…³å†…å®¹ï¼š{len(irrelevant_files)} ä¸ª")
            for r in irrelevant_files:
                print(f"   - {r.get('title')} (åˆ†æ•°: {r.get('score', 0):.3f})")

if __name__ == "__main__":
    test_search_deduplication()
